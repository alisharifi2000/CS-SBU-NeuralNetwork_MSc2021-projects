{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment 4.ipynb",
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1Iw3j1KD42sBjJCooioxStJeZuKpJCzBj",
      "authorship_tag": "ABX9TyMKxleC1ZNS0ap3UY0zLw0Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZahraMousakhani/CS-SBU-NeuralNetwork_MSc2021-projects/blob/main/ZahraMousakhani-99422187/project4/assignment_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6AU8AfDXi_R",
        "outputId": "de9b0707-10e6-47ad-c8da-a5f5ec79730e"
      },
      "source": [
        "!pip install kaggle"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2021.5.30)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.41.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (5.0.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7CgpmdW5jdGlvbiBfdXBsb2FkRmlsZXMoaW5wdXRJZCwgb3V0cHV0SWQpIHsKICBjb25zdCBzdGVwcyA9IHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCk7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICAvLyBDYWNoZSBzdGVwcyBvbiB0aGUgb3V0cHV0RWxlbWVudCB0byBtYWtlIGl0IGF2YWlsYWJsZSBmb3IgdGhlIG5leHQgY2FsbAogIC8vIHRvIHVwbG9hZEZpbGVzQ29udGludWUgZnJvbSBQeXRob24uCiAgb3V0cHV0RWxlbWVudC5zdGVwcyA9IHN0ZXBzOwoKICByZXR1cm4gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpOwp9CgovLyBUaGlzIGlzIHJvdWdobHkgYW4gYXN5bmMgZ2VuZXJhdG9yIChub3Qgc3VwcG9ydGVkIGluIHRoZSBicm93c2VyIHlldCksCi8vIHdoZXJlIHRoZXJlIGFyZSBtdWx0aXBsZSBhc3luY2hyb25vdXMgc3RlcHMgYW5kIHRoZSBQeXRob24gc2lkZSBpcyBnb2luZwovLyB0byBwb2xsIGZvciBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcC4KLy8gVGhpcyB1c2VzIGEgUHJvbWlzZSB0byBibG9jayB0aGUgcHl0aG9uIHNpZGUgb24gY29tcGxldGlvbiBvZiBlYWNoIHN0ZXAsCi8vIHRoZW4gcGFzc2VzIHRoZSByZXN1bHQgb2YgdGhlIHByZXZpb3VzIHN0ZXAgYXMgdGhlIGlucHV0IHRvIHRoZSBuZXh0IHN0ZXAuCmZ1bmN0aW9uIF91cGxvYWRGaWxlc0NvbnRpbnVlKG91dHB1dElkKSB7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICBjb25zdCBzdGVwcyA9IG91dHB1dEVsZW1lbnQuc3RlcHM7CgogIGNvbnN0IG5leHQgPSBzdGVwcy5uZXh0KG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSk7CiAgcmV0dXJuIFByb21pc2UucmVzb2x2ZShuZXh0LnZhbHVlLnByb21pc2UpLnRoZW4oKHZhbHVlKSA9PiB7CiAgICAvLyBDYWNoZSB0aGUgbGFzdCBwcm9taXNlIHZhbHVlIHRvIG1ha2UgaXQgYXZhaWxhYmxlIHRvIHRoZSBuZXh0CiAgICAvLyBzdGVwIG9mIHRoZSBnZW5lcmF0b3IuCiAgICBvdXRwdXRFbGVtZW50Lmxhc3RQcm9taXNlVmFsdWUgPSB2YWx1ZTsKICAgIHJldHVybiBuZXh0LnZhbHVlLnJlc3BvbnNlOwogIH0pOwp9CgovKioKICogR2VuZXJhdG9yIGZ1bmN0aW9uIHdoaWNoIGlzIGNhbGxlZCBiZXR3ZWVuIGVhY2ggYXN5bmMgc3RlcCBvZiB0aGUgdXBsb2FkCiAqIHByb2Nlc3MuCiAqIEBwYXJhbSB7c3RyaW5nfSBpbnB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIGlucHV0IGZpbGUgcGlja2VyIGVsZW1lbnQuCiAqIEBwYXJhbSB7c3RyaW5nfSBvdXRwdXRJZCBFbGVtZW50IElEIG9mIHRoZSBvdXRwdXQgZGlzcGxheS4KICogQHJldHVybiB7IUl0ZXJhYmxlPCFPYmplY3Q+fSBJdGVyYWJsZSBvZiBuZXh0IHN0ZXBzLgogKi8KZnVuY3Rpb24qIHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IGlucHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKGlucHV0SWQpOwogIGlucHV0RWxlbWVudC5kaXNhYmxlZCA9IGZhbHNlOwoKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIG91dHB1dEVsZW1lbnQuaW5uZXJIVE1MID0gJyc7CgogIGNvbnN0IHBpY2tlZFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgaW5wdXRFbGVtZW50LmFkZEV2ZW50TGlzdGVuZXIoJ2NoYW5nZScsIChlKSA9PiB7CiAgICAgIHJlc29sdmUoZS50YXJnZXQuZmlsZXMpOwogICAgfSk7CiAgfSk7CgogIGNvbnN0IGNhbmNlbCA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2J1dHRvbicpOwogIGlucHV0RWxlbWVudC5wYXJlbnRFbGVtZW50LmFwcGVuZENoaWxkKGNhbmNlbCk7CiAgY2FuY2VsLnRleHRDb250ZW50ID0gJ0NhbmNlbCB1cGxvYWQnOwogIGNvbnN0IGNhbmNlbFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgY2FuY2VsLm9uY2xpY2sgPSAoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9OwogIH0pOwoKICAvLyBXYWl0IGZvciB0aGUgdXNlciB0byBwaWNrIHRoZSBmaWxlcy4KICBjb25zdCBmaWxlcyA9IHlpZWxkIHsKICAgIHByb21pc2U6IFByb21pc2UucmFjZShbcGlja2VkUHJvbWlzZSwgY2FuY2VsUHJvbWlzZV0pLAogICAgcmVzcG9uc2U6IHsKICAgICAgYWN0aW9uOiAnc3RhcnRpbmcnLAogICAgfQogIH07CgogIGNhbmNlbC5yZW1vdmUoKTsKCiAgLy8gRGlzYWJsZSB0aGUgaW5wdXQgZWxlbWVudCBzaW5jZSBmdXJ0aGVyIHBpY2tzIGFyZSBub3QgYWxsb3dlZC4KICBpbnB1dEVsZW1lbnQuZGlzYWJsZWQgPSB0cnVlOwoKICBpZiAoIWZpbGVzKSB7CiAgICByZXR1cm4gewogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgICAgfQogICAgfTsKICB9CgogIGZvciAoY29uc3QgZmlsZSBvZiBmaWxlcykgewogICAgY29uc3QgbGkgPSBkb2N1bWVudC5jcmVhdGVFbGVtZW50KCdsaScpOwogICAgbGkuYXBwZW5kKHNwYW4oZmlsZS5uYW1lLCB7Zm9udFdlaWdodDogJ2JvbGQnfSkpOwogICAgbGkuYXBwZW5kKHNwYW4oCiAgICAgICAgYCgke2ZpbGUudHlwZSB8fCAnbi9hJ30pIC0gJHtmaWxlLnNpemV9IGJ5dGVzLCBgICsKICAgICAgICBgbGFzdCBtb2RpZmllZDogJHsKICAgICAgICAgICAgZmlsZS5sYXN0TW9kaWZpZWREYXRlID8gZmlsZS5sYXN0TW9kaWZpZWREYXRlLnRvTG9jYWxlRGF0ZVN0cmluZygpIDoKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgJ24vYSd9IC0gYCkpOwogICAgY29uc3QgcGVyY2VudCA9IHNwYW4oJzAlIGRvbmUnKTsKICAgIGxpLmFwcGVuZENoaWxkKHBlcmNlbnQpOwoKICAgIG91dHB1dEVsZW1lbnQuYXBwZW5kQ2hpbGQobGkpOwoKICAgIGNvbnN0IGZpbGVEYXRhUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICAgIGNvbnN0IHJlYWRlciA9IG5ldyBGaWxlUmVhZGVyKCk7CiAgICAgIHJlYWRlci5vbmxvYWQgPSAoZSkgPT4gewogICAgICAgIHJlc29sdmUoZS50YXJnZXQucmVzdWx0KTsKICAgICAgfTsKICAgICAgcmVhZGVyLnJlYWRBc0FycmF5QnVmZmVyKGZpbGUpOwogICAgfSk7CiAgICAvLyBXYWl0IGZvciB0aGUgZGF0YSB0byBiZSByZWFkeS4KICAgIGxldCBmaWxlRGF0YSA9IHlpZWxkIHsKICAgICAgcHJvbWlzZTogZmlsZURhdGFQcm9taXNlLAogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbnRpbnVlJywKICAgICAgfQogICAgfTsKCiAgICAvLyBVc2UgYSBjaHVua2VkIHNlbmRpbmcgdG8gYXZvaWQgbWVzc2FnZSBzaXplIGxpbWl0cy4gU2VlIGIvNjIxMTU2NjAuCiAgICBsZXQgcG9zaXRpb24gPSAwOwogICAgZG8gewogICAgICBjb25zdCBsZW5ndGggPSBNYXRoLm1pbihmaWxlRGF0YS5ieXRlTGVuZ3RoIC0gcG9zaXRpb24sIE1BWF9QQVlMT0FEX1NJWkUpOwogICAgICBjb25zdCBjaHVuayA9IG5ldyBVaW50OEFycmF5KGZpbGVEYXRhLCBwb3NpdGlvbiwgbGVuZ3RoKTsKICAgICAgcG9zaXRpb24gKz0gbGVuZ3RoOwoKICAgICAgY29uc3QgYmFzZTY0ID0gYnRvYShTdHJpbmcuZnJvbUNoYXJDb2RlLmFwcGx5KG51bGwsIGNodW5rKSk7CiAgICAgIHlpZWxkIHsKICAgICAgICByZXNwb25zZTogewogICAgICAgICAgYWN0aW9uOiAnYXBwZW5kJywKICAgICAgICAgIGZpbGU6IGZpbGUubmFtZSwKICAgICAgICAgIGRhdGE6IGJhc2U2NCwKICAgICAgICB9LAogICAgICB9OwoKICAgICAgbGV0IHBlcmNlbnREb25lID0gZmlsZURhdGEuYnl0ZUxlbmd0aCA9PT0gMCA/CiAgICAgICAgICAxMDAgOgogICAgICAgICAgTWF0aC5yb3VuZCgocG9zaXRpb24gLyBmaWxlRGF0YS5ieXRlTGVuZ3RoKSAqIDEwMCk7CiAgICAgIHBlcmNlbnQudGV4dENvbnRlbnQgPSBgJHtwZXJjZW50RG9uZX0lIGRvbmVgOwoKICAgIH0gd2hpbGUgKHBvc2l0aW9uIDwgZmlsZURhdGEuYnl0ZUxlbmd0aCk7CiAgfQoKICAvLyBBbGwgZG9uZS4KICB5aWVsZCB7CiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICB9CiAgfTsKfQoKc2NvcGUuZ29vZ2xlID0gc2NvcGUuZ29vZ2xlIHx8IHt9OwpzY29wZS5nb29nbGUuY29sYWIgPSBzY29wZS5nb29nbGUuY29sYWIgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYi5fZmlsZXMgPSB7CiAgX3VwbG9hZEZpbGVzLAogIF91cGxvYWRGaWxlc0NvbnRpbnVlLAp9Owp9KShzZWxmKTsK",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "5KZTmB3DmFRR",
        "outputId": "0f2da5aa-3304-4b59-f3ff-650e1f9e4317"
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-9fb01d23-53cb-40dd-9bd4-24ac95dc894d\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-9fb01d23-53cb-40dd-9bd4-24ac95dc894d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"zahramousakhani\",\"key\":\"755da9f324f8575f4914cdb3228a0941\"}'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZM6mf4jlHqn"
      },
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PFweOsktwCn8",
        "outputId": "f4fd49c3-1b57-4466-f631-c3d5d1677d65"
      },
      "source": [
        "!kaggle competitions download -c nlp-getting-started\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.4)\n",
            "Downloading test.csv to /content\n",
            "  0% 0.00/411k [00:00<?, ?B/s]\n",
            "100% 411k/411k [00:00<00:00, 61.6MB/s]\n",
            "Downloading sample_submission.csv to /content\n",
            "  0% 0.00/22.2k [00:00<?, ?B/s]\n",
            "100% 22.2k/22.2k [00:00<00:00, 43.2MB/s]\n",
            "Downloading train.csv to /content\n",
            "  0% 0.00/965k [00:00<?, ?B/s]\n",
            "100% 965k/965k [00:00<00:00, 64.0MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9_rr-ANznEl",
        "outputId": "2dfacbc5-af7e-429a-bd7c-f65e321923eb"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive  kaggle.json  sample_data  sample_submission.csv\ttest.csv  train.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTiKxON9xqtZ",
        "outputId": "289164f5-1dfb-428c-c85f-dceb96341063"
      },
      "source": [
        "!pip install torchtext"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.7/dist-packages (0.10.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext) (2.23.0)\n",
            "Requirement already satisfied: torch==1.9.0 in /usr/local/lib/python3.7/dist-packages (from torchtext) (1.9.0+cu102)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext) (1.19.5)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (3.0.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0->torchtext) (3.7.4.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MqbBl3Hq0uUu",
        "outputId": "d2fcd88f-a120-4d88-b4f6-64484eb72059"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import warnings\n",
        "if not sys.warnoptions:\n",
        "    warnings.simplefilter(\"ignore\")\n",
        "    \n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "\n",
        "# Libraries and packages for text (pre-)processing \n",
        "import string\n",
        "import re\n",
        "import nltk\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import time\n",
        "from torchtext.legacy import data\n",
        "import torch\n",
        "from torchtext import data\n",
        "import torch.nn as nn\n",
        "\n",
        "print(\"Python version:\", sys.version)\n",
        "print(\"Version info.:\", sys.version_info)\n",
        "print(\"pandas version:\", pd.__version__)\n",
        "print(\"numpy version:\", np.__version__)\n",
        "print(\"skearn version:\", sklearn.__version__)\n",
        "print(\"re version:\", re.__version__)\n",
        "print(\"nltk version:\", nltk.__version__)\n",
        "\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python version: 3.7.10 (default, May  3 2021, 02:48:31) \n",
            "[GCC 7.5.0]\n",
            "Version info.: sys.version_info(major=3, minor=7, micro=10, releaselevel='final', serial=0)\n",
            "pandas version: 1.1.5\n",
            "numpy version: 1.19.5\n",
            "skearn version: 0.22.2.post1\n",
            "re version: 2.2.1\n",
            "nltk version: 3.2.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        },
        "id": "nbtvmGjrfuy-",
        "outputId": "e1b53f7f-ceac-4d84-ee16-e6d5f6a5b7be"
      },
      "source": [
        "#read the data:\n",
        "train_df = pd.read_csv(\"/content/train.csv\")\n",
        "display(train_df.shape, train_df.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(7613, 5)"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword  ...                                               text target\n",
              "0   1     NaN  ...  Our Deeds are the Reason of this #earthquake M...      1\n",
              "1   4     NaN  ...             Forest fire near La Ronge Sask. Canada      1\n",
              "2   5     NaN  ...  All residents asked to 'shelter in place' are ...      1\n",
              "3   6     NaN  ...  13,000 people receive #wildfires evacuation or...      1\n",
              "4   7     NaN  ...  Just got sent this photo from Ruby #Alaska as ...      1\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "2jflkwAmgDD5",
        "outputId": "3134b180-b3cb-42f7-d28f-0ac0cfa8fcf7"
      },
      "source": [
        "#some early exploration:\n",
        "display(train_df[~train_df[\"location\"].isnull()].head())\n",
        "display(train_df[train_df[\"target\"] == 0][\"text\"].values[1])\n",
        "display(train_df[train_df[\"target\"] == 1][\"text\"].values[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>48</td>\n",
              "      <td>ablaze</td>\n",
              "      <td>Birmingham</td>\n",
              "      <td>@bbcmtd Wholesale Markets ablaze http://t.co/l...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>49</td>\n",
              "      <td>ablaze</td>\n",
              "      <td>Est. September 2012 - Bristol</td>\n",
              "      <td>We always try to bring the heavy. #metal #RT h...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>50</td>\n",
              "      <td>ablaze</td>\n",
              "      <td>AFRICA</td>\n",
              "      <td>#AFRICANBAZE: Breaking news:Nigeria flag set a...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>52</td>\n",
              "      <td>ablaze</td>\n",
              "      <td>Philadelphia, PA</td>\n",
              "      <td>Crying out for more! Set me ablaze</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>53</td>\n",
              "      <td>ablaze</td>\n",
              "      <td>London, UK</td>\n",
              "      <td>On plus side LOOK AT THE SKY LAST NIGHT IT WAS...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    id keyword  ...                                               text target\n",
              "31  48  ablaze  ...  @bbcmtd Wholesale Markets ablaze http://t.co/l...      1\n",
              "32  49  ablaze  ...  We always try to bring the heavy. #metal #RT h...      0\n",
              "33  50  ablaze  ...  #AFRICANBAZE: Breaking news:Nigeria flag set a...      1\n",
              "34  52  ablaze  ...                 Crying out for more! Set me ablaze      0\n",
              "35  53  ablaze  ...  On plus side LOOK AT THE SKY LAST NIGHT IT WAS...      0\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'I love fruits'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Forest fire near La Ronge Sask. Canada'"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "RrDYQ9cGgbRP",
        "outputId": "a737dc4c-58b8-4c3c-dcc7-f0d741541fcc"
      },
      "source": [
        "train_df[\"text_clean\"] = train_df[\"text\"].apply(lambda x: x.lower())\n",
        "display(train_df.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>text_clean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "      <td>our deeds are the reason of this #earthquake m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "      <td>forest fire near la ronge sask. canada</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "      <td>all residents asked to 'shelter in place' are ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "      <td>just got sent this photo from ruby #alaska as ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword  ... target                                         text_clean\n",
              "0   1     NaN  ...      1  our deeds are the reason of this #earthquake m...\n",
              "1   4     NaN  ...      1             forest fire near la ronge sask. canada\n",
              "2   5     NaN  ...      1  all residents asked to 'shelter in place' are ...\n",
              "3   6     NaN  ...      1  13,000 people receive #wildfires evacuation or...\n",
              "4   7     NaN  ...      1  just got sent this photo from ruby #alaska as ...\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSUAYhvzhFMt",
        "outputId": "d61a23a4-0b7b-4fb3-c848-43da5eb2649d"
      },
      "source": [
        "!pip install contractions"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting contractions\n",
            "  Downloading https://files.pythonhosted.org/packages/93/f4/0ec4a458e4368cc3be2c799411ecf0bc961930e566dadb9624563821b3a6/contractions-0.0.52-py2.py3-none-any.whl\n",
            "Collecting textsearch>=0.0.21\n",
            "  Downloading https://files.pythonhosted.org/packages/d3/fe/021d7d76961b5ceb9f8d022c4138461d83beff36c3938dc424586085e559/textsearch-0.0.21-py2.py3-none-any.whl\n",
            "Collecting pyahocorasick\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7f/c2/eae730037ae1cbbfaa229d27030d1d5e34a1e41114b21447d1202ae9c220/pyahocorasick-1.4.2.tar.gz (321kB)\n",
            "\u001b[K     |████████████████████████████████| 327kB 2.9MB/s \n",
            "\u001b[?25hCollecting anyascii\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/14/666cd44bf53f36a961544af592cb5c5c800013f9c51a4745af8d7c17362a/anyascii-0.2.0-py3-none-any.whl (283kB)\n",
            "\u001b[K     |████████████████████████████████| 286kB 19.2MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyahocorasick\n",
            "  Building wheel for pyahocorasick (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyahocorasick: filename=pyahocorasick-1.4.2-cp37-cp37m-linux_x86_64.whl size=85401 sha256=e62b126533aa73e7fadf903f03fdbcf0961d23681c4d556583f2ab142006bb5b\n",
            "  Stored in directory: /root/.cache/pip/wheels/3a/03/34/77e3ece0bba8b86bfac88a79f923b36d805cad63caeba38842\n",
            "Successfully built pyahocorasick\n",
            "Installing collected packages: pyahocorasick, anyascii, textsearch, contractions\n",
            "Successfully installed anyascii-0.2.0 contractions-0.0.52 pyahocorasick-1.4.2 textsearch-0.0.21\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yaARilSvhy6j",
        "outputId": "0b9e1481-cf37-4e93-8423-33689fd6968e"
      },
      "source": [
        "import contractions\n",
        "\n",
        "# Test\n",
        "test_text = \"\"\"\n",
        "            Y'all can't expand contractions I'd think. I'd like to know how I'd done that! \n",
        "            We're going to the zoo and I don't think I'll be home for dinner.\n",
        "            Theyre going to the zoo and she'll be home for dinner.\n",
        "            We should've do it in here but we shouldn't've eat it\n",
        "            \"\"\"\n",
        "print(\"Test: \", contractions.fix(test_text))\n",
        "\n",
        "train_df[\"text_clean\"] = train_df[\"text_clean\"].apply(lambda x: contractions.fix(x))\n",
        "\n",
        "# double check\n",
        "print(train_df[\"text\"][67])\n",
        "print(train_df[\"text_clean\"][67])\n",
        "print(train_df[\"text\"][12])\n",
        "print(train_df[\"text_clean\"][12])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test:  \n",
            "            you all cannot expand contractions I would think. I would like to know how I would done that! \n",
            "            we are going to the zoo and I do not think I will be home for dinner.\n",
            "            they are going to the zoo and she will be home for dinner.\n",
            "            We should have do it in here but we should not have eat it\n",
            "            \n",
            "'I can't have kids cuz I got in a bicycle accident &amp; split my testicles. it's impossible for me to have kids' MICHAEL YOU ARE THE FATHER\n",
            "'i cannot have kids cuz i got in a bicycle accident &amp; split my testicles. it is impossible for me to have kids' michael you are the father\n",
            "#raining #flooding #Florida #TampaBay #Tampa 18 or 19 days. I've lost count \n",
            "#raining #flooding #florida #tampabay #tampa 18 or 19 days. I have lost count \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWPGyR-FiZI0"
      },
      "source": [
        "def remove_URL(text):\n",
        "    \"\"\"\n",
        "        Remove URLs from a sample string\n",
        "    \"\"\"\n",
        "    return re.sub(r\"https?://\\S+|www\\.\\S+\", \"\", text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eNDMwHmkicUK",
        "outputId": "92ad02a8-fae5-405d-b0a0-16e4b96b13a2"
      },
      "source": [
        "# remove urls from the text\n",
        "train_df[\"text_clean\"] = train_df[\"text_clean\"].apply(lambda x: remove_URL(x))\n",
        "\n",
        "# double check\n",
        "print(train_df[\"text\"][31])\n",
        "print(train_df[\"text_clean\"][31])\n",
        "print(train_df[\"text\"][37])\n",
        "print(train_df[\"text_clean\"][37])\n",
        "print(train_df[\"text\"][62])\n",
        "print(train_df[\"text_clean\"][62])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "@bbcmtd Wholesale Markets ablaze http://t.co/lHYXEOHY6C\n",
            "@bbcmtd wholesale markets ablaze \n",
            "INEC Office in Abia Set Ablaze - http://t.co/3ImaomknnA\n",
            "inec office in abia set ablaze - \n",
            "Rene Ablaze &amp; Jacinta - Secret 2k13 (Fallen Skies Edit) - Mar 30 2013  https://t.co/7MLMsUzV1Z\n",
            "rene ablaze &amp; jacinta - secret 2k13 (fallen skies edit) - mar 30 2013  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4gOza36iqQC"
      },
      "source": [
        "def remove_html(text):\n",
        "    \"\"\"\n",
        "        Remove the html in sample text\n",
        "    \"\"\"\n",
        "    html = re.compile(r\"<.*?>|&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});\")\n",
        "    return re.sub(html, \"\", text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vkodXfxzit9e",
        "outputId": "e1b3085c-67b3-43a3-ca64-15f1de972b28"
      },
      "source": [
        "# remove html from the text\n",
        "train_df[\"text_clean\"] = train_df[\"text_clean\"].apply(lambda x: remove_html(x))\n",
        "\n",
        "# double check\n",
        "print(train_df[\"text\"][62])\n",
        "print(train_df[\"text_clean\"][62])\n",
        "print(train_df[\"text\"][7385])\n",
        "print(train_df[\"text_clean\"][7385])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Rene Ablaze &amp; Jacinta - Secret 2k13 (Fallen Skies Edit) - Mar 30 2013  https://t.co/7MLMsUzV1Z\n",
            "rene ablaze  jacinta - secret 2k13 (fallen skies edit) - mar 30 2013  \n",
            "NW Michigan #WindStorm (Sheer) Recovery Updates: Leelanau &amp; Grand Traverse - State of Emergency 2b extended http://t.co/OSKfyj8CK7 #BeSafe\n",
            "nw michigan #windstorm (sheer) recovery updates: leelanau  grand traverse - state of emergency 2b extended  #besafe\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ivv4DtXhjD69"
      },
      "source": [
        "def remove_non_ascii(text):\n",
        "    \"\"\"\n",
        "        Remove non-ASCII characters \n",
        "    \"\"\"\n",
        "    return re.sub(r'[^\\x00-\\x7f]',r'', text) # or ''.join([x for x in text if x in string.printable])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F0ryClDijG74",
        "outputId": "2fe07c73-34f3-4e5c-fe73-46d9ffe550b7"
      },
      "source": [
        "# remove non-ascii characters from the text\n",
        "train_df[\"text_clean\"] = train_df[\"text_clean\"].apply(lambda x: remove_non_ascii(x))\n",
        "\n",
        "# double check\n",
        "print(train_df[\"text\"][38])\n",
        "print(train_df[\"text_clean\"][38])\n",
        "print(train_df[\"text\"][7586])\n",
        "print(train_df[\"text_clean\"][7586])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Barbados #Bridgetown JAMAICA ÛÒ Two cars set ablaze: SANTA CRUZ ÛÓ Head of the St Elizabeth Police Superintende...  http://t.co/wDUEaj8Q4J\n",
            "barbados #bridgetown jamaica  two cars set ablaze: santa cruz  head of the st elizabeth police superintende...  \n",
            "#Sismo DETECTADO #JapÌ_n 15:41:07 Seismic intensity 0 Iwate Miyagi JST #?? http://t.co/gMoUl9zQ2Q\n",
            "#sismo detectado #jap_n 15:41:07 seismic intensity 0 iwate miyagi jst #?? \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "846Y7SiSk3Ew"
      },
      "source": [
        "def remove_punct(text):\n",
        " \n",
        "  #return re.sub(r'[]!\"$%&\\'()*+,./:;=#@?[\\\\^_`{|}~-]+', \"\", text)\n",
        "  return text.translate(str.maketrans('', '', string.punctuation))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s01VTZBLlSHr",
        "outputId": "ff50a782-6bbd-4a57-cecb-18c63c4f30f8"
      },
      "source": [
        "# remove punctuations from the text\n",
        "train_df[\"text_clean\"] = train_df[\"text_clean\"].apply(lambda x: remove_punct(x))\n",
        "\n",
        "# double check\n",
        "print(train_df[\"text\"][5])\n",
        "print(train_df[\"text_clean\"][5])\n",
        "print(train_df[\"text\"][7597])\n",
        "print(train_df[\"text_clean\"][7597])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "#RockyFire Update => California Hwy. 20 closed in both directions due to Lake County fire - #CAfire #wildfires\n",
            "rockyfire update  california hwy 20 closed in both directions due to lake county fire  cafire wildfires\n",
            "#??? #?? #??? #??? MH370: Aircraft debris found on La Reunion is from missing Malaysia Airlines ... http://t.co/5B7qT2YxdA\n",
            "    mh370 aircraft debris found on la reunion is from missing malaysia airlines  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUhpxzYPmErG"
      },
      "source": [
        "def other_clean(text):\n",
        "        \"\"\"\n",
        "            Other manual text cleaning techniques\n",
        "        \"\"\"\n",
        "        # Typos, slang and other\n",
        "        sample_typos_slang = {\n",
        "                                \"w/e\": \"whatever\",\n",
        "                                \"usagov\": \"usa government\",\n",
        "                                \"recentlu\": \"recently\",\n",
        "                                \"ph0tos\": \"photos\",\n",
        "                                \"amirite\": \"am i right\",\n",
        "                                \"exp0sed\": \"exposed\",\n",
        "                                \"<3\": \"love\",\n",
        "                                \"luv\": \"love\",\n",
        "                                \"amageddon\": \"armageddon\",\n",
        "                                \"trfc\": \"traffic\",\n",
        "                                \"16yr\": \"16 year\"\n",
        "                                }\n",
        "        # Acronyms\n",
        "        sample_acronyms =  { \n",
        "                            \"mh370\": \"malaysia airlines flight 370\",\n",
        "                            \"okwx\": \"oklahoma city weather\",\n",
        "                            \"arwx\": \"arkansas weather\",    \n",
        "                            \"gawx\": \"georgia weather\",  \n",
        "                            \"scwx\": \"south carolina weather\",  \n",
        "                            \"cawx\": \"california weather\",\n",
        "                            \"tnwx\": \"tennessee weather\",\n",
        "                            \"azwx\": \"arizona weather\",  \n",
        "                            \"alwx\": \"alabama weather\",\n",
        "                            \"usnwsgov\": \"united states national weather service\",\n",
        "                            \"2mw\": \"tomorrow\"\n",
        "                            }\n",
        "        # Some common abbreviations \n",
        "        sample_abbr = {\n",
        "                        \"$\" : \" dollar \",\n",
        "                        \"€\" : \" euro \",\n",
        "                        \"4ao\" : \"for adults only\",\n",
        "                        \"a.m\" : \"before midday\",\n",
        "                        \"a3\" : \"anytime anywhere anyplace\",\n",
        "                        \"aamof\" : \"as a matter of fact\",\n",
        "                        \"acct\" : \"account\",\n",
        "                        \"adih\" : \"another day in hell\",\n",
        "                        \"afaic\" : \"as far as i am concerned\",\n",
        "                        \"afaict\" : \"as far as i can tell\",\n",
        "                        \"afaik\" : \"as far as i know\",\n",
        "                        \"afair\" : \"as far as i remember\",\n",
        "                        \"afk\" : \"away from keyboard\",\n",
        "                        \"app\" : \"application\",\n",
        "                        \"approx\" : \"approximately\",\n",
        "                        \"apps\" : \"applications\",\n",
        "                        \"asap\" : \"as soon as possible\",\n",
        "                        \"asl\" : \"age, sex, location\",\n",
        "                        \"atk\" : \"at the keyboard\",\n",
        "                        \"ave.\" : \"avenue\",\n",
        "                        \"aymm\" : \"are you my mother\",\n",
        "                        \"ayor\" : \"at your own risk\", \n",
        "                        \"b&b\" : \"bed and breakfast\",\n",
        "                        \"b+b\" : \"bed and breakfast\",\n",
        "                        \"b.c\" : \"before christ\",\n",
        "                        \"b2b\" : \"business to business\",\n",
        "                        \"b2c\" : \"business to customer\",\n",
        "                        \"b4\" : \"before\",\n",
        "                        \"b4n\" : \"bye for now\",\n",
        "                        \"b@u\" : \"back at you\",\n",
        "                        \"bae\" : \"before anyone else\",\n",
        "                        \"bak\" : \"back at keyboard\",\n",
        "                        \"bbbg\" : \"bye bye be good\",\n",
        "                        \"bbc\" : \"british broadcasting corporation\",\n",
        "                        \"bbias\" : \"be back in a second\",\n",
        "                        \"bbl\" : \"be back later\",\n",
        "                        \"bbs\" : \"be back soon\",\n",
        "                        \"be4\" : \"before\",\n",
        "                        \"bfn\" : \"bye for now\",\n",
        "                        \"blvd\" : \"boulevard\",\n",
        "                        \"bout\" : \"about\",\n",
        "                        \"brb\" : \"be right back\",\n",
        "                        \"bros\" : \"brothers\",\n",
        "                        \"brt\" : \"be right there\",\n",
        "                        \"bsaaw\" : \"big smile and a wink\",\n",
        "                        \"btw\" : \"by the way\",\n",
        "                        \"bwl\" : \"bursting with laughter\",                             \n",
        "                        \"c/o\" : \"care of\",\n",
        "                        \"cet\" : \"central european time\",\n",
        "                        \"cf\" : \"compare\",\n",
        "                        \"cia\" : \"central intelligence agency\",\n",
        "                        \"csl\" : \"can not stop laughing\",\n",
        "                        \"cu\" : \"see you\",\n",
        "                        \"cul8r\" : \"see you later\",\n",
        "                        \"cv\" : \"curriculum vitae\",\n",
        "                        \"cwot\" : \"complete waste of time\",\n",
        "                        \"cya\" : \"see you\",\n",
        "                        \"cyt\" : \"see you tomorrow\",\n",
        "                        \"dae\" : \"does anyone else\",\n",
        "                        \"dbmib\" : \"do not bother me i am busy\",\n",
        "                        \"diy\" : \"do it yourself\",\n",
        "                        \"dm\" : \"direct message\",\n",
        "                        \"dwh\" : \"during work hours\",\n",
        "                        \"e123\" : \"easy as one two three\",\n",
        "                        \"eet\" : \"eastern european time\",\n",
        "                        \"eg\" : \"example\",\n",
        "                        \"embm\" : \"early morning business meeting\",\n",
        "                        \"encl\" : \"enclosed\",\n",
        "                        \"encl.\" : \"enclosed\",\n",
        "                        \"etc\" : \"and so on\",\n",
        "                        \"faq\" : \"frequently asked questions\",\n",
        "                        \"fawc\" : \"for anyone who cares\",\n",
        "                        \"fb\" : \"facebook\",\n",
        "                        \"fc\" : \"fingers crossed\",\n",
        "                        \"fig\" : \"figure\",\n",
        "                        \"fimh\" : \"forever in my heart\", \n",
        "                        \"ft.\" : \"feet\",\n",
        "                        \"ft\" : \"featuring\",\n",
        "                        \"ftl\" : \"for the loss\",\n",
        "                        \"ftw\" : \"for the win\",\n",
        "                        \"fwiw\" : \"for what it is worth\",\n",
        "                        \"fyi\" : \"for your information\",\n",
        "                        \"g9\" : \"genius\",\n",
        "                        \"gahoy\" : \"get a hold of yourself\",\n",
        "                        \"gal\" : \"get a life\",\n",
        "                        \"gcse\" : \"general certificate of secondary education\",\n",
        "                        \"gfn\" : \"gone for now\",\n",
        "                        \"gg\" : \"good game\",\n",
        "                        \"gl\" : \"good luck\",\n",
        "                        \"glhf\" : \"good luck have fun\",\n",
        "                        \"gmt\" : \"greenwich mean time\",\n",
        "                        \"gmta\" : \"great minds think alike\",\n",
        "                        \"gn\" : \"good night\",\n",
        "                        \"g.o.a.t\" : \"greatest of all time\",\n",
        "                        \"goat\" : \"greatest of all time\",\n",
        "                        \"goi\" : \"get over it\",\n",
        "                        \"gps\" : \"global positioning system\",\n",
        "                        \"gr8\" : \"great\",\n",
        "                        \"gratz\" : \"congratulations\",\n",
        "                        \"gyal\" : \"girl\",\n",
        "                        \"h&c\" : \"hot and cold\",   \n",
        "                        \"hp\" : \"horsepower\",\n",
        "                        \"hr\" : \"hour\",\n",
        "                        \"hrh\" : \"his royal highness\",\n",
        "                        \"ht\" : \"height\",\n",
        "                        \"ibrb\" : \"i will be right back\",\n",
        "                        \"ic\" : \"i see\",\n",
        "                        \"icq\" : \"i seek you\",\n",
        "                        \"icymi\" : \"in case you missed it\",\n",
        "                        \"idc\" : \"i do not care\",\n",
        "                        \"idgadf\" : \"i do not give a damn fuck\",\n",
        "                        \"idgaf\" : \"i do not give a fuck\",\n",
        "                        \"idk\" : \"i do not know\",\n",
        "                        \"ie\" : \"that is\",\n",
        "                        \"i.e\" : \"that is\",\n",
        "                        \"ifyp\" : \"i feel your pain\",\n",
        "                        \"IG\" : \"instagram\",\n",
        "                        \"iirc\" : \"if i remember correctly\",\n",
        "                        \"ilu\" : \"i love you\",\n",
        "                        \"ily\" : \"i love you\",\n",
        "                        \"imho\" : \"in my humble opinion\",\n",
        "                        \"imo\" : \"in my opinion\",\n",
        "                        \"imu\" : \"i miss you\",\n",
        "                        \"iow\" : \"in other words\",\n",
        "                        \"irl\" : \"in real life\",\n",
        "                        \"j4f\" : \"just for fun\",\n",
        "                        \"jic\" : \"just in case\", \n",
        "                        \"jk\" : \"just kidding\",\n",
        "                        \"jsyk\" : \"just so you know\",\n",
        "                        \"l8r\" : \"later\",\n",
        "                        \"lb\" : \"pound\",\n",
        "                        \"lbs\" : \"pounds\",\n",
        "                        \"ldr\" : \"long distance relationship\",\n",
        "                        \"lmao\" : \"laugh my ass off\",\n",
        "                        \"lmfao\" : \"laugh my fucking ass off\",\n",
        "                        \"lol\" : \"laughing out loud\",\n",
        "                        \"ltd\" : \"limited\",\n",
        "                        \"ltns\" : \"long time no see\",\n",
        "                        \"m8\" : \"mate\",\n",
        "                        \"mf\" : \"motherfucker\",\n",
        "                        \"mfs\" : \"motherfuckers\",\n",
        "                        \"mfw\" : \"my face when\",\n",
        "                        \"mofo\" : \"motherfucker\",\n",
        "                        \"mph\" : \"miles per hour\",\n",
        "                        \"mr\" : \"mister\",\n",
        "                        \"mrw\" : \"my reaction when\",\n",
        "                        \"ms\" : \"miss\",\n",
        "                        \"mte\" : \"my thoughts exactly\",\n",
        "                        \"nagi\" : \"not a good idea\",\n",
        "                        \"nbc\" : \"national broadcasting company\",\n",
        "                        \"nbd\" : \"not big deal\",\n",
        "                        \"nfs\" : \"not for sale\",\n",
        "                        \"ngl\" : \"not going to lie\",   \n",
        "                        \"nhs\" : \"national health service\",\n",
        "                        \"nrn\" : \"no reply necessary\",\n",
        "                        \"nsfl\" : \"not safe for life\",\n",
        "                        \"nsfw\" : \"not safe for work\",\n",
        "                        \"nth\" : \"nice to have\",\n",
        "                        \"nvr\" : \"never\",\n",
        "                        \"nyc\" : \"new york city\",\n",
        "                        \"oc\" : \"original content\",\n",
        "                        \"og\" : \"original\",\n",
        "                        \"ohp\" : \"overhead projector\",\n",
        "                        \"oic\" : \"oh i see\",\n",
        "                        \"omdb\" : \"over my dead body\",\n",
        "                        \"omg\" : \"oh my god\",\n",
        "                        \"omw\" : \"on my way\",\n",
        "                        \"p.a\" : \"per annum\",\n",
        "                        \"p.m\" : \"after midday\",\n",
        "                        \"pm\" : \"prime minister\",\n",
        "                        \"poc\" : \"people of color\",\n",
        "                        \"pov\" : \"point of view\",\n",
        "                        \"pp\" : \"pages\",\n",
        "                        \"ppl\" : \"people\",\n",
        "                        \"prw\" : \"parents are watching\",\n",
        "                        \"ps\" : \"postscript\",\n",
        "                        \"pt\" : \"point\", \n",
        "                        \"ptb\" : \"please text back\",\n",
        "                        \"pto\" : \"please turn over\",\n",
        "                        \"qpsa\" : \"what happens\", #\"que pasa\",\n",
        "                        \"ratchet\" : \"rude\",\n",
        "                        \"rbtl\" : \"read between the lines\",\n",
        "                        \"rlrt\" : \"real life retweet\", \n",
        "                        \"rofl\" : \"rolling on the floor laughing\",\n",
        "                        \"roflol\" : \"rolling on the floor laughing out loud\",\n",
        "                        \"rotflmao\" : \"rolling on the floor laughing my ass off\",\n",
        "                        \"rt\" : \"retweet\",\n",
        "                        \"ruok\" : \"are you ok\",\n",
        "                        \"sfw\" : \"safe for work\",\n",
        "                        \"sk8\" : \"skate\",\n",
        "                        \"smh\" : \"shake my head\",\n",
        "                        \"sq\" : \"square\",\n",
        "                        \"srsly\" : \"seriously\", \n",
        "                        \"ssdd\" : \"same stuff different day\",\n",
        "                        \"tbh\" : \"to be honest\",\n",
        "                        \"tbs\" : \"tablespooful\",\n",
        "                        \"tbsp\" : \"tablespooful\",\n",
        "                        \"tfw\" : \"that feeling when\",\n",
        "                        \"thks\" : \"thank you\",\n",
        "                        \"tho\" : \"though\",\n",
        "                        \"thx\" : \"thank you\",\n",
        "                        \"tia\" : \"thanks in advance\",\n",
        "                        \"til\" : \"today i learned\",\n",
        "                        \"tl;dr\" : \"too long i did not read\",\n",
        "                        \"tldr\" : \"too long i did not read\",\n",
        "                        \"tmb\" : \"tweet me back\",\n",
        "                        \"tntl\" : \"trying not to laugh\",\n",
        "                        \"ttyl\" : \"talk to you later\",\n",
        "                        \"u\" : \"you\",\n",
        "                        \"u2\" : \"you too\",\n",
        "                        \"u4e\" : \"yours for ever\",\n",
        "                        \"utc\" : \"coordinated universal time\",\n",
        "                        \"w/\" : \"with\",\n",
        "                        \"w/o\" : \"without\",\n",
        "                        \"w8\" : \"wait\",\n",
        "                        \"wassup\" : \"what is up\",\n",
        "                        \"wb\" : \"welcome back\",\n",
        "                        \"wtf\" : \"what the fuck\",\n",
        "                        \"wtg\" : \"way to go\",\n",
        "                        \"wtpa\" : \"where the party at\",\n",
        "                        \"wuf\" : \"where are you from\",\n",
        "                        \"wuzup\" : \"what is up\",\n",
        "                        \"wywh\" : \"wish you were here\",\n",
        "                        \"yd\" : \"yard\",\n",
        "                        \"ygtr\" : \"you got that right\",\n",
        "                        \"ynk\" : \"you never know\",\n",
        "                        \"zzz\" : \"sleeping bored and tired\"\n",
        "                        }  \n",
        "        sample_typos_slang_pattern = re.compile(r'(?<!\\w)(' + '|'.join(re.escape(key) for key in sample_typos_slang.keys()) + r')(?!\\w)')\n",
        "        sample_acronyms_pattern = re.compile(r'(?<!\\w)(' + '|'.join(re.escape(key) for key in sample_acronyms.keys()) + r')(?!\\w)')\n",
        "        sample_abbr_pattern = re.compile(r'(?<!\\w)(' + '|'.join(re.escape(key) for key in sample_abbr.keys()) + r')(?!\\w)')\n",
        "        \n",
        "        text = sample_typos_slang_pattern.sub(lambda x: sample_typos_slang[x.group()], text)\n",
        "        text = sample_acronyms_pattern.sub(lambda x: sample_acronyms[x.group()], text)\n",
        "        text = sample_abbr_pattern.sub(lambda x: sample_abbr[x.group()], text)\n",
        "        \n",
        "        return text                                               "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fUuhChVcn_JI",
        "outputId": "ae668cf2-20a9-42d4-afcc-dafd9fa1f68d"
      },
      "source": [
        "# Test\n",
        "test_text = \"\"\"\n",
        "            brb with some sample ph0tos I lov u. I need some $ for 2mw.\n",
        "            \"\"\"\n",
        "print(\"Test: \", other_clean(test_text))\n",
        "\n",
        "# remove punctuations from the text\n",
        "train_df[\"text_clean\"] = train_df[\"text_clean\"].apply(lambda x: other_clean(x))\n",
        "\n",
        "# double check\n",
        "print(train_df[\"text\"][1844])\n",
        "print(train_df[\"text_clean\"][1844])\n",
        "print(train_df[\"text\"][4409])\n",
        "print(train_df[\"text_clean\"][4409])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test:  \n",
            "            be right back with some sample photos I lov you. I need some  dollar  for tomorrow.\n",
            "            \n",
            "MH370: Intact part lifts odds plane glided not crashed into sea http://t.co/8pdnHH6tzH\n",
            "malaysia airlines flight 370 intact part lifts odds plane glided not crashed into sea \n",
            "@USAgov Koreans are performing hijacking of the Tokyo Olympic Games.https://t.co/APkSnpLXZj\n",
            "usa government koreans are performing hijacking of the tokyo olympic games\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "0MYbKLXkW0Ka",
        "outputId": "1e4e8e49-583b-496c-9a65-fd13bd6b71d5"
      },
      "source": [
        "# Tokenizing the tweet base texts.\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "train_df[\"tokenized\"] = train_df[\"text_clean\"].apply(word_tokenize)\n",
        "train_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>text_clean</th>\n",
              "      <th>tokenized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "      <td>our deeds are the reason of this earthquake ma...</td>\n",
              "      <td>[our, deeds, are, the, reason, of, this, earth...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "      <td>forest fire near la ronge sask canada</td>\n",
              "      <td>[forest, fire, near, la, ronge, sask, canada]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "      <td>all residents asked to shelter in place are be...</td>\n",
              "      <td>[all, residents, asked, to, shelter, in, place...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "      <td>13000 people receive wildfires evacuation orde...</td>\n",
              "      <td>[13000, people, receive, wildfires, evacuation...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "      <td>just got sent this photo from ruby alaska as s...</td>\n",
              "      <td>[just, got, sent, this, photo, from, ruby, ala...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  ...                                          tokenized\n",
              "0   1  ...  [our, deeds, are, the, reason, of, this, earth...\n",
              "1   4  ...      [forest, fire, near, la, ronge, sask, canada]\n",
              "2   5  ...  [all, residents, asked, to, shelter, in, place...\n",
              "3   6  ...  [13000, people, receive, wildfires, evacuation...\n",
              "4   7  ...  [just, got, sent, this, photo, from, ruby, ala...\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "xPX8ENmeYhsF",
        "outputId": "b5156e1b-234a-48a6-9eea-a58963e364ac"
      },
      "source": [
        "# Removing stopwords.\n",
        "nltk.download(\"stopwords\")\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "stop = set(stopwords.words('english'))\n",
        "train_df['stopwords_removed'] = train_df['tokenized'].apply(lambda x: [word for word in x if word not in stop])\n",
        "train_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>text_clean</th>\n",
              "      <th>tokenized</th>\n",
              "      <th>stopwords_removed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "      <td>our deeds are the reason of this earthquake ma...</td>\n",
              "      <td>[our, deeds, are, the, reason, of, this, earth...</td>\n",
              "      <td>[deeds, reason, earthquake, may, allah, forgiv...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "      <td>forest fire near la ronge sask canada</td>\n",
              "      <td>[forest, fire, near, la, ronge, sask, canada]</td>\n",
              "      <td>[forest, fire, near, la, ronge, sask, canada]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "      <td>all residents asked to shelter in place are be...</td>\n",
              "      <td>[all, residents, asked, to, shelter, in, place...</td>\n",
              "      <td>[residents, asked, shelter, place, notified, o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "      <td>13000 people receive wildfires evacuation orde...</td>\n",
              "      <td>[13000, people, receive, wildfires, evacuation...</td>\n",
              "      <td>[13000, people, receive, wildfires, evacuation...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "      <td>just got sent this photo from ruby alaska as s...</td>\n",
              "      <td>[just, got, sent, this, photo, from, ruby, ala...</td>\n",
              "      <td>[got, sent, photo, ruby, alaska, smoke, wildfi...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  ...                                  stopwords_removed\n",
              "0   1  ...  [deeds, reason, earthquake, may, allah, forgiv...\n",
              "1   4  ...      [forest, fire, near, la, ronge, sask, canada]\n",
              "2   5  ...  [residents, asked, shelter, place, notified, o...\n",
              "3   6  ...  [13000, people, receive, wildfires, evacuation...\n",
              "4   7  ...  [got, sent, photo, ruby, alaska, smoke, wildfi...\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbWmzwSy2jmw"
      },
      "source": [
        "#stemming: \n",
        "from nltk.stem import SnowballStemmer\n",
        "\n",
        "def snowball_stemmer(text):\n",
        "    \"\"\"\n",
        "        Stem words in list of tokenized words with SnowballStemmer\n",
        "    \"\"\"\n",
        "    stemmer = nltk.SnowballStemmer(\"english\")\n",
        "    stems = [stemmer.stem(i) for i in text]\n",
        "    return stems"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "6tjOJrDo37Y-",
        "outputId": "75920303-76e5-4eb7-874b-9abdf14be4f7"
      },
      "source": [
        "train_df['snowball_stemmer'] = train_df['stopwords_removed'].apply(lambda x: snowball_stemmer(x))\n",
        "train_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>text_clean</th>\n",
              "      <th>tokenized</th>\n",
              "      <th>stopwords_removed</th>\n",
              "      <th>snowball_stemmer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "      <td>our deeds are the reason of this earthquake ma...</td>\n",
              "      <td>[our, deeds, are, the, reason, of, this, earth...</td>\n",
              "      <td>[deeds, reason, earthquake, may, allah, forgiv...</td>\n",
              "      <td>[deed, reason, earthquak, may, allah, forgiv, us]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "      <td>forest fire near la ronge sask canada</td>\n",
              "      <td>[forest, fire, near, la, ronge, sask, canada]</td>\n",
              "      <td>[forest, fire, near, la, ronge, sask, canada]</td>\n",
              "      <td>[forest, fire, near, la, rong, sask, canada]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "      <td>all residents asked to shelter in place are be...</td>\n",
              "      <td>[all, residents, asked, to, shelter, in, place...</td>\n",
              "      <td>[residents, asked, shelter, place, notified, o...</td>\n",
              "      <td>[resid, ask, shelter, place, notifi, offic, ev...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "      <td>13000 people receive wildfires evacuation orde...</td>\n",
              "      <td>[13000, people, receive, wildfires, evacuation...</td>\n",
              "      <td>[13000, people, receive, wildfires, evacuation...</td>\n",
              "      <td>[13000, peopl, receiv, wildfir, evacu, order, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "      <td>just got sent this photo from ruby alaska as s...</td>\n",
              "      <td>[just, got, sent, this, photo, from, ruby, ala...</td>\n",
              "      <td>[got, sent, photo, ruby, alaska, smoke, wildfi...</td>\n",
              "      <td>[got, sent, photo, rubi, alaska, smoke, wildfi...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  ...                                   snowball_stemmer\n",
              "0   1  ...  [deed, reason, earthquak, may, allah, forgiv, us]\n",
              "1   4  ...       [forest, fire, near, la, rong, sask, canada]\n",
              "2   5  ...  [resid, ask, shelter, place, notifi, offic, ev...\n",
              "3   6  ...  [13000, peopl, receiv, wildfir, evacu, order, ...\n",
              "4   7  ...  [got, sent, photo, rubi, alaska, smoke, wildfi...\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8xZEVYJ-4A0U",
        "outputId": "ba124f32-6309-488a-9750-99b765d996c4"
      },
      "source": [
        "from nltk.corpus import wordnet\n",
        "from nltk.corpus import brown\n",
        "nltk.download('wordnet')\n",
        "nltk.download('brown')\n",
        "wordnet_map = {\"N\":wordnet.NOUN, \n",
        "               \"V\":wordnet.VERB, \n",
        "               \"J\":wordnet.ADJ, \n",
        "               \"R\":wordnet.ADV\n",
        "              }\n",
        "    \n",
        "train_sents = brown.tagged_sents(categories='news')\n",
        "t0 = nltk.DefaultTagger('NN')\n",
        "t1 = nltk.UnigramTagger(train_sents, backoff=t0)\n",
        "t2 = nltk.BigramTagger(train_sents, backoff=t1)\n",
        "\n",
        "def pos_tag_wordnet(text, pos_tag_type=\"pos_tag\"):\n",
        "    \"\"\"\n",
        "        Create pos_tag with wordnet format\n",
        "    \"\"\"\n",
        "    pos_tagged_text = t2.tag(text)\n",
        "    \n",
        "    # map the pos tagging output with wordnet output \n",
        "    pos_tagged_text = [(word, wordnet_map.get(pos_tag[0])) if pos_tag[0] in wordnet_map.keys() else (word, wordnet.NOUN) for (word, pos_tag) in pos_tagged_text ]\n",
        "    return pos_tagged_text"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Package brown is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        },
        "id": "BnaxPmd-9fOt",
        "outputId": "8742d5ac-1aa1-4c0a-e3b8-3ce7fc324bbe"
      },
      "source": [
        "train_df['combined_postag_wnet'] = train_df['stopwords_removed'].apply(lambda x: pos_tag_wordnet(x))\n",
        "\n",
        "train_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>text_clean</th>\n",
              "      <th>tokenized</th>\n",
              "      <th>stopwords_removed</th>\n",
              "      <th>snowball_stemmer</th>\n",
              "      <th>combined_postag_wnet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "      <td>our deeds are the reason of this earthquake ma...</td>\n",
              "      <td>[our, deeds, are, the, reason, of, this, earth...</td>\n",
              "      <td>[deeds, reason, earthquake, may, allah, forgiv...</td>\n",
              "      <td>[deed, reason, earthquak, may, allah, forgiv, us]</td>\n",
              "      <td>[(deeds, n), (reason, n), (earthquake, n), (ma...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "      <td>forest fire near la ronge sask canada</td>\n",
              "      <td>[forest, fire, near, la, ronge, sask, canada]</td>\n",
              "      <td>[forest, fire, near, la, ronge, sask, canada]</td>\n",
              "      <td>[forest, fire, near, la, rong, sask, canada]</td>\n",
              "      <td>[(forest, n), (fire, n), (near, n), (la, n), (...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "      <td>all residents asked to shelter in place are be...</td>\n",
              "      <td>[all, residents, asked, to, shelter, in, place...</td>\n",
              "      <td>[residents, asked, shelter, place, notified, o...</td>\n",
              "      <td>[resid, ask, shelter, place, notifi, offic, ev...</td>\n",
              "      <td>[(residents, n), (asked, v), (shelter, n), (pl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "      <td>13000 people receive wildfires evacuation orde...</td>\n",
              "      <td>[13000, people, receive, wildfires, evacuation...</td>\n",
              "      <td>[13000, people, receive, wildfires, evacuation...</td>\n",
              "      <td>[13000, peopl, receiv, wildfir, evacu, order, ...</td>\n",
              "      <td>[(13000, n), (people, n), (receive, v), (wildf...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "      <td>just got sent this photo from ruby alaska as s...</td>\n",
              "      <td>[just, got, sent, this, photo, from, ruby, ala...</td>\n",
              "      <td>[got, sent, photo, ruby, alaska, smoke, wildfi...</td>\n",
              "      <td>[got, sent, photo, rubi, alaska, smoke, wildfi...</td>\n",
              "      <td>[(got, v), (sent, v), (photo, n), (ruby, n), (...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  ...                               combined_postag_wnet\n",
              "0   1  ...  [(deeds, n), (reason, n), (earthquake, n), (ma...\n",
              "1   4  ...  [(forest, n), (fire, n), (near, n), (la, n), (...\n",
              "2   5  ...  [(residents, n), (asked, v), (shelter, n), (pl...\n",
              "3   6  ...  [(13000, n), (people, n), (receive, v), (wildf...\n",
              "4   7  ...  [(got, v), (sent, v), (photo, n), (ruby, n), (...\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GNpBTFCCBTK"
      },
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "def lemmatize_word(text):\n",
        "    \"\"\"\n",
        "        Lemmatize the tokenized words\n",
        "    \"\"\"\n",
        "\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    lemma = [lemmatizer.lemmatize(word, tag) for word, tag in text]\n",
        "    return lemma"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "id": "VqD2jEGBBehH",
        "outputId": "11e15ab6-d666-4072-a365-1c05952cacc4"
      },
      "source": [
        "%time \n",
        "\n",
        "# Test with POS Tagging\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "train_df[\"lemmatize_word_w_pos\"] = train_df[\"combined_postag_wnet\"].apply(lambda x: lemmatize_word(x))\n",
        "train_df['lemmatize_word_w_pos'] = train_df['lemmatize_word_w_pos'].apply(lambda x: [word for word in x if word not in stop]) # double check to remove stop words\n",
        "train_df['lemmatize_text'] = [' '.join(map(str, l)) for l in train_df['lemmatize_word_w_pos']] # join back to text\n",
        "\n",
        "train_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
            "Wall time: 5.48 µs\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>text_clean</th>\n",
              "      <th>tokenized</th>\n",
              "      <th>stopwords_removed</th>\n",
              "      <th>snowball_stemmer</th>\n",
              "      <th>combined_postag_wnet</th>\n",
              "      <th>lemmatize_word_w_pos</th>\n",
              "      <th>lemmatize_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "      <td>our deeds are the reason of this earthquake ma...</td>\n",
              "      <td>[our, deeds, are, the, reason, of, this, earth...</td>\n",
              "      <td>[deeds, reason, earthquake, may, allah, forgiv...</td>\n",
              "      <td>[deed, reason, earthquak, may, allah, forgiv, us]</td>\n",
              "      <td>[(deeds, n), (reason, n), (earthquake, n), (ma...</td>\n",
              "      <td>[deed, reason, earthquake, may, allah, forgive...</td>\n",
              "      <td>deed reason earthquake may allah forgive u</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "      <td>forest fire near la ronge sask canada</td>\n",
              "      <td>[forest, fire, near, la, ronge, sask, canada]</td>\n",
              "      <td>[forest, fire, near, la, ronge, sask, canada]</td>\n",
              "      <td>[forest, fire, near, la, rong, sask, canada]</td>\n",
              "      <td>[(forest, n), (fire, n), (near, n), (la, n), (...</td>\n",
              "      <td>[forest, fire, near, la, ronge, sask, canada]</td>\n",
              "      <td>forest fire near la ronge sask canada</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "      <td>all residents asked to shelter in place are be...</td>\n",
              "      <td>[all, residents, asked, to, shelter, in, place...</td>\n",
              "      <td>[residents, asked, shelter, place, notified, o...</td>\n",
              "      <td>[resid, ask, shelter, place, notifi, offic, ev...</td>\n",
              "      <td>[(residents, n), (asked, v), (shelter, n), (pl...</td>\n",
              "      <td>[resident, ask, shelter, place, notified, offi...</td>\n",
              "      <td>resident ask shelter place notified officer ev...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "      <td>13000 people receive wildfires evacuation orde...</td>\n",
              "      <td>[13000, people, receive, wildfires, evacuation...</td>\n",
              "      <td>[13000, people, receive, wildfires, evacuation...</td>\n",
              "      <td>[13000, peopl, receiv, wildfir, evacu, order, ...</td>\n",
              "      <td>[(13000, n), (people, n), (receive, v), (wildf...</td>\n",
              "      <td>[13000, people, receive, wildfire, evacuation,...</td>\n",
              "      <td>13000 people receive wildfire evacuation order...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "      <td>just got sent this photo from ruby alaska as s...</td>\n",
              "      <td>[just, got, sent, this, photo, from, ruby, ala...</td>\n",
              "      <td>[got, sent, photo, ruby, alaska, smoke, wildfi...</td>\n",
              "      <td>[got, sent, photo, rubi, alaska, smoke, wildfi...</td>\n",
              "      <td>[(got, v), (sent, v), (photo, n), (ruby, n), (...</td>\n",
              "      <td>[get, send, photo, ruby, alaska, smoke, wildfi...</td>\n",
              "      <td>get send photo ruby alaska smoke wildfire pour...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  ...                                     lemmatize_text\n",
              "0   1  ...         deed reason earthquake may allah forgive u\n",
              "1   4  ...              forest fire near la ronge sask canada\n",
              "2   5  ...  resident ask shelter place notified officer ev...\n",
              "3   6  ...  13000 people receive wildfire evacuation order...\n",
              "4   7  ...  get send photo ruby alaska smoke wildfire pour...\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "T2dTni7xBzLs",
        "outputId": "640af6d7-5acd-4005-e7a4-3704252a8576"
      },
      "source": [
        "display(train_df[\"text\"][0], train_df[\"lemmatize_text\"][0])\n",
        "display(train_df[\"text\"][5], train_df[\"lemmatize_text\"][5])\n",
        "display(train_df[\"text\"][10], train_df[\"lemmatize_text\"][10])\n",
        "display(train_df[\"text\"][15], train_df[\"lemmatize_text\"][15])\n",
        "display(train_df[\"text\"][20], train_df[\"lemmatize_text\"][20])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'deed reason earthquake may allah forgive u'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'#RockyFire Update => California Hwy. 20 closed in both directions due to Lake County fire - #CAfire #wildfires'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'rockyfire update california hwy 20 close direction due lake county fire cafire wildfire'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Three people died from the heat wave so far'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'three people die heat wave far'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"What's up man?\""
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'man'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'this is ridiculous....'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'ridiculous'"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GeAn0797sOMm"
      },
      "source": [
        "def get_average_vec(tokens_list, vector, generate_missing=False, k=300):\n",
        "    \"\"\"\n",
        "        Calculate average embedding value of sentence from each word vector\n",
        "    \"\"\"\n",
        "    if len(tokens_list)<1:\n",
        "        return np.zeros(k)\n",
        "    \n",
        "    if generate_missing:\n",
        "        vectorized = [vector[word] if word in vector else np.random.rand(k) for word in tokens_list]\n",
        "    else:\n",
        "        vectorized = [vector[word] if word in vector else np.zeros(k) for word in tokens_list]\n",
        "    \n",
        "    length = len(vectorized)\n",
        "    summed = np.sum(vectorized, axis=0)\n",
        "    averaged = np.divide(summed, length)\n",
        "    return averaged\n",
        "\n",
        "def get_embeddings(vectors, text, generate_missing=False, k=300):\n",
        "    \"\"\"\n",
        "        create the sentence embedding\n",
        "    \"\"\"\n",
        "    embeddings = text.apply(lambda x: get_average_vec(x, vectors, generate_missing=generate_missing, k=k))\n",
        "    return list(embeddings)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "db4w8HUGl-T8"
      },
      "source": [
        "import gensim\n",
        "from gensim.models.fasttext import FastText\n",
        "\n",
        "fasttext_path = \"/content/drive/MyDrive/wiki-news-300d-1M.vec\"\n",
        "fasttext_model = gensim.models.KeyedVectors.load_word2vec_format(fasttext_path, binary=False, limit=200000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDkLn5-gpFtM",
        "outputId": "885f2682-3fb1-40db-a7cf-704ea08ac668"
      },
      "source": [
        "from keras.layers import Embedding\n",
        "embeddings_fasttext = get_embeddings(fasttext_model, train_df[\"lemmatize_text\"], k=300)\n",
        "\n",
        "print(\"Embedding matrix size\", len(embeddings_fasttext), len(embeddings_fasttext[0]))\n",
        "print(\"The sentence: \\\"%s\\\" got embedding values: \" % train_df[\"lemmatize_text\"][0])\n",
        "print(embeddings_fasttext[0])\n",
        "print(type(embeddings_fasttext))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Embedding matrix size 7613 300\n",
            "The sentence: \"deed reason earthquake may allah forgive u\" got embedding values: \n",
            "[-8.09166668e-02  2.61404759e-02 -8.73142836e-02 -3.69428569e-02\n",
            "  1.73714293e-02  4.03738089e-02  1.19119056e-02 -2.96238094e-02\n",
            "  1.21804762e-01  4.34142850e-02 -2.36714286e-02 -2.98738095e-02\n",
            "  5.00333325e-02 -2.49952377e-02 -2.62000006e-02  2.73166672e-02\n",
            " -1.57404756e-02 -1.61595243e-02 -2.85976184e-02  7.77619022e-02\n",
            " -1.63690476e-02 -1.13026191e-01 -3.10547621e-02 -2.75714294e-02\n",
            " -6.89023813e-02 -5.33142867e-02  2.94666670e-02  1.26283331e-01\n",
            "  3.59476194e-02 -9.56166665e-02  4.42857155e-02  2.53380938e-02\n",
            " -1.39238087e-02 -2.98023802e-02  5.93452381e-02  6.58619040e-02\n",
            " -1.11547623e-02  1.53952374e-02  5.92904766e-02 -1.74500004e-02\n",
            " -2.33333374e-03 -9.57619045e-03 -9.73023806e-02 -3.89999918e-03\n",
            "  2.21000003e-02  1.47904770e-02  4.90023823e-02  2.88071422e-02\n",
            "  8.64047606e-02  3.05714297e-03 -1.81666667e-02 -4.32404758e-02\n",
            " -5.74880958e-01 -4.76190484e-03  1.78571507e-03  5.96190463e-03\n",
            " -7.99999836e-04 -9.34619041e-02  5.42380883e-03 -2.31666604e-03\n",
            "  1.85404762e-02  1.76595233e-02 -1.57778573e-01  4.48833325e-02\n",
            " -3.58809517e-02 -2.47214290e-02  4.40095242e-02  2.98309520e-02\n",
            "  3.23642852e-02  5.24619048e-02  1.51547627e-02 -1.32761908e-02\n",
            "  2.10095238e-02  1.50040474e-01  1.93047614e-02 -4.03571388e-03\n",
            " -5.91261903e-02 -1.90238092e-02  3.94095237e-02 -8.10119056e-02\n",
            "  1.22333335e-02 -1.63928571e-02 -6.08333396e-03 -1.18854762e-01\n",
            "  1.85023812e-02  2.22166662e-02 -6.20333342e-02  1.24119048e-02\n",
            "  2.72238107e-02 -4.28428577e-02  4.58404764e-02  2.52214282e-02\n",
            "  4.67428578e-02 -6.18333340e-02 -2.93333303e-03  3.91785722e-02\n",
            "  3.22309522e-02 -2.98333329e-02 -1.15523810e-02 -2.83334146e-04\n",
            " -1.57207144e-01 -9.74761843e-03 -2.93095258e-03 -9.84285681e-03\n",
            " -7.68523802e-02  1.80357150e-02  4.69071407e-02  1.51190480e-02\n",
            " -8.97309527e-02 -2.44333342e-02 -2.22928570e-02  2.20238109e-03\n",
            "  8.87952396e-02  4.39285726e-02 -4.41071433e-02  5.92119054e-02\n",
            "  1.95119035e-02 -7.48785725e-02 -6.03238098e-02 -2.65961904e-01\n",
            "  2.31119053e-02 -1.87547626e-02 -1.92880952e-02 -6.99690467e-02\n",
            " -3.20761907e-02  1.63716669e-01  3.84000000e-02  5.32142836e-03\n",
            " -3.99547629e-02  2.29809527e-02  1.75880954e-02  3.33761912e-02\n",
            "  3.59761898e-02  4.93857131e-02 -5.94404758e-02 -1.39450000e-01\n",
            " -5.92142876e-03 -1.01619044e-02 -4.32904763e-02  2.35785715e-02\n",
            "  3.56904700e-03 -7.57142836e-03  5.80000009e-02  2.36421428e-01\n",
            "  3.52666676e-02 -4.38666667e-02  5.65428577e-02  7.51428558e-02\n",
            "  3.42142869e-02  1.10952378e-03  1.58357141e-02  5.00761900e-02\n",
            " -3.63261901e-02  3.60952380e-03 -2.46190482e-02  4.78738091e-02\n",
            "  2.04285703e-03  8.73333297e-03 -4.32666671e-02 -7.10714309e-03\n",
            "  1.35309529e-02 -2.25761906e-02  4.16714291e-02  1.71207142e-01\n",
            " -3.28928582e-02  3.25761900e-02  1.38064284e-01 -2.80333335e-02\n",
            " -1.68095237e-02 -7.23571420e-03  4.00880949e-02 -5.26904726e-03\n",
            " -2.37833326e-02  1.47666670e-02  2.31119058e-02  2.10738094e-02\n",
            "  1.86942857e-01 -7.15714183e-03 -9.38095314e-03 -8.60476179e-03\n",
            "  2.15619037e-02  5.68261901e-02 -2.52523807e-02 -3.76190444e-03\n",
            " -2.91238090e-02 -5.85642854e-02 -3.53404757e-02 -2.57857142e-02\n",
            "  1.39666669e-02  6.91190469e-02  6.11357138e-02  8.65404758e-02\n",
            " -2.64666667e-02  5.13333308e-03 -3.12690476e-02 -4.03880952e-02\n",
            " -3.74380951e-02 -4.73595234e-02  6.42309520e-02 -1.14999986e-03\n",
            "  2.95738095e-02 -9.12857142e-02 -1.66500011e-02 -7.64523819e-03\n",
            "  2.99999973e-04  2.78285714e-02  1.77476186e-02  2.48404759e-02\n",
            "  2.88595242e-02 -3.41119046e-02 -1.61738098e-02 -1.27380963e-02\n",
            " -5.64999943e-03  3.40476186e-02  3.37619047e-02 -6.19428575e-02\n",
            "  1.17735713e-01 -2.08571436e-02 -8.08547635e-02  1.11997618e-01\n",
            " -7.10595230e-02 -3.78833323e-02 -5.70000003e-02 -5.37380936e-02\n",
            " -4.76547623e-02 -1.11830953e-01 -5.19428577e-02  1.74285725e-03\n",
            "  7.24047613e-03 -9.04833336e-02  2.97857144e-02 -1.62190479e-02\n",
            "  2.83530953e-01 -1.18140477e-01  6.94047685e-03 -3.50571431e-02\n",
            " -1.33190472e-02 -9.52452367e-02 -1.73821428e-01 -5.55880951e-02\n",
            "  5.33690458e-02 -2.13309512e-02  2.95000032e-03 -9.39047636e-03\n",
            " -5.94238100e-02  1.11971428e-01  5.07119043e-02 -3.16166669e-02\n",
            "  6.64404747e-02  2.75476190e-01  3.32285713e-02 -3.63523814e-02\n",
            "  1.28280952e-01  3.08809490e-03  3.50428562e-02 -7.12857095e-03\n",
            " -2.11357134e-02 -2.14785713e-02 -2.46714284e-02  4.19523779e-03\n",
            " -5.78095226e-03 -1.01476185e-02  4.82142829e-03  3.13476199e-02\n",
            " -2.66540474e-01  5.98571437e-02  2.34404770e-02 -1.99095237e-02\n",
            "  1.23619061e-02 -2.66809530e-02 -3.52690477e-02  2.13214292e-02\n",
            "  2.06976189e-02  4.77285711e-02 -2.65857133e-02  4.95714291e-03\n",
            " -7.58190487e-02 -8.61452384e-02  3.80499995e-02  3.11595234e-02\n",
            "  2.68809508e-03  5.83547609e-02  2.36285714e-02 -2.55952385e-02\n",
            "  1.26690477e-02 -3.88809529e-02  1.18414287e-01 -1.03952383e-02\n",
            "  9.16666659e-03  4.35738095e-02  2.62380946e-02  1.23714284e-02\n",
            " -4.50238077e-03  4.60690471e-02  2.82595239e-02  2.25785720e-02\n",
            "  1.77857139e-02 -2.51190479e-02  2.50714419e-03  6.78095219e-03]\n",
            "<class 'list'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9WwEdodslxP",
        "outputId": "399c509e-2fac-46a6-9139-47665fa516b8"
      },
      "source": [
        "# split data into train and validation \n",
        "print(train_df.shape)\n",
        "train_df_split, valid_df = train_test_split(train_df)\n",
        "print(train_df_split.shape)\n",
        "print(valid_df.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7613, 12)\n",
            "(5709, 12)\n",
            "(1904, 12)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEVgbQuxiVSC"
      },
      "source": [
        "SEED = 42\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2C2aDgkBoSaM",
        "outputId": "2b3bce7d-802c-4ca7-f339-6687c295fa59"
      },
      "source": [
        "!pip install -U torchtext==0.10.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: torchtext==0.10.0 in /usr/local/lib/python3.7/dist-packages (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: torch==1.9.0 in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.0) (1.9.0+cu102)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.0) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.0) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.0) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0->torchtext==0.10.0) (3.7.4.3)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (2021.5.30)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xq5m6mh-iZHJ"
      },
      "source": [
        "from torchtext import data, legacy\n",
        "from torchtext.legacy.data import Field,LabelField, TabularDataset, BucketIterator, Iterator, Dataset, Example, BucketIterator\n",
        "#from torchtext.data import Field\n",
        "#from torchtext.data import LabelField\n",
        "\n",
        "TEXT = Field( include_lengths = True)\n",
        "LABEL =LabelField(dtype = torch.float)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9omQvZD0onU"
      },
      "source": [
        "class DataFrameDataset(Dataset):\n",
        "\n",
        "    def __init__(self, df, fields, is_test=False, **kwargs):\n",
        "        examples = []     \n",
        "      \n",
        "        for i, row in df.iterrows():\n",
        "            label = row.target if not is_test else None\n",
        "            text = row.lemmatize_text\n",
        "            examples.append(legacy.data.Example.fromlist([text, label], fields))\n",
        "\n",
        "        super().__init__(examples, fields, **kwargs)\n",
        "\n",
        "    @staticmethod\n",
        "    def sort_key(ex):\n",
        "        return len(ex.lemmatize_text)\n",
        "\n",
        "    @classmethod\n",
        "    def splits(cls, fields, train_df, val_df=None, test_df=None, **kwargs):\n",
        "        train_data, val_data, test_data = (None, None, None)\n",
        "        data_field = fields\n",
        "\n",
        "        if train_df is not None:\n",
        "            train_data = cls(train_df.copy(), data_field, **kwargs)\n",
        "        if val_df is not None:\n",
        "            val_data = cls(val_df.copy(), data_field, **kwargs)\n",
        "        if test_df is not None:\n",
        "            test_data = cls(test_df.copy(), data_field, True, **kwargs)\n",
        "\n",
        "        return tuple(d for d in (train_data, val_data, test_data) if d is not None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8EalgXy2Vk8"
      },
      "source": [
        "fields = [(\"lemmatize_text\",TEXT), (\"label\",LABEL)]\n",
        "\n",
        "train_ds, val_ds = DataFrameDataset.splits(fields, train_df=train_df_split, val_df=valid_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddJiIQLkBBjl",
        "outputId": "b288d77a-0627-43e0-9ee0-f2dbbefae963"
      },
      "source": [
        "# Lets look at a random example\n",
        "print(vars(train_ds[15]))\n",
        "\n",
        "# Check the type \n",
        "print(type(train_ds[15]))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'lemmatize_text': ['tube', 'strike', 'live', 'late', 'travel', 'update', 'london', 'engulf', 'chaos', 'crosslondon', 'travel', 'accepte'], 'label': 1}\n",
            "<class 'torchtext.legacy.data.example.Example'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97ZDGYu9TPHr",
        "outputId": "5cf5f86e-3c32-45c0-8504-7f55704c04e0"
      },
      "source": [
        "from collections import Counter\n",
        "MAX_VOCAB_SIZE = 25000\n",
        "#vocab = Counter(train_ds[:]['lemmatize_text'])  # create a dictionary\n",
        "#vocab = sorted(vocab, key=vocab.get, reverse=True)\n",
        "#MAX_VOCAB_SIZE = len(vocab)\n",
        "print(MAX_VOCAB_SIZE)\n",
        "TEXT.build_vocab(train_ds, \n",
        "                 max_size = MAX_VOCAB_SIZE, \n",
        "                 vectors = 'glove.6B.200d',\n",
        "                 unk_init = torch.Tensor.zero_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r.vector_cache/glove.6B.zip: 0.00B [00:00, ?B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "25000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ".vector_cache/glove.6B.zip: 862MB [02:41, 5.35MB/s]                           \n",
            "100%|█████████▉| 398983/400000 [00:29<00:00, 13473.74it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBfLI5RuWpr5"
      },
      "source": [
        "LABEL.build_vocab(train_ds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjLdrhdpWzVS"
      },
      "source": [
        "BATCH_SIZE = 128\n",
        "#sort avaz kardam\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iterator, valid_iterator = legacy.data.BucketIterator.splits(\n",
        "    (train_ds, val_ds), \n",
        "    batch_size = BATCH_SIZE,\n",
        "    sort_within_batch = True,\n",
        "    device = device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TgCFH33qW_8G"
      },
      "source": [
        "# Hyperparameters\n",
        "#embeddinf_dim was 200\n",
        "num_epochs = 100\n",
        "learning_rate = 0.001\n",
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 200\n",
        "HIDDEN_DIM = 256\n",
        "OUTPUT_DIM = 1\n",
        "N_LAYERS = 2\n",
        "BIDIRECTIONAL = True\n",
        "DROPOUT = 0.2\n",
        "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token] # padding"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56N_kp3BcdAQ"
      },
      "source": [
        "class LSTM_net(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, \n",
        "                 bidirectional, dropout, pad_idx):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n",
        "        \n",
        "        self.rnn = nn.LSTM(embedding_dim, \n",
        "                           hidden_dim, \n",
        "                           num_layers=n_layers, \n",
        "                           bidirectional=bidirectional, \n",
        "                           dropout=dropout)\n",
        "        \n",
        "        self.fc1 = nn.Linear(hidden_dim * 2, hidden_dim)\n",
        "        \n",
        "        self.fc2 = nn.Linear(hidden_dim, 1)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, text, text_lengths):\n",
        "        \n",
        "        # text = [sent len, batch size]\n",
        "        \n",
        "        embedded = self.embedding(text)\n",
        "        # embedded = [sent len, batch size, emb dim]\n",
        "        \n",
        "        #pack sequence\n",
        "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths)\n",
        "        \n",
        "        packed_output, (hidden, cell) = self.rnn(packed_embedded)\n",
        "        \n",
        "        #unpack sequence\n",
        "        # output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output)\n",
        "\n",
        "        # output = [sent len, batch size, hid dim * num directions]\n",
        "        # output over padding tokens are zero tensors\n",
        "        \n",
        "        # hidden = [num layers * num directions, batch size, hid dim]\n",
        "        # cell = [num layers * num directions, batch size, hid dim]\n",
        "        \n",
        "        # concat the final forward (hidden[-2,:,:]) and backward (hidden[-1,:,:]) hidden layers\n",
        "        # and apply dropout\n",
        "        \n",
        "        hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n",
        "        output = self.fc1(hidden)\n",
        "        output = self.dropout(self.fc2(output))\n",
        "        #hidden = [batch size, hid dim * num directions]\n",
        "            \n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I40z7XkkcqTY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e99ce408-76ed-41d6-cedc-d24be66ff681"
      },
      "source": [
        "#creating instance of our LSTM_net class\n",
        "\n",
        "model = LSTM_net(INPUT_DIM, \n",
        "            EMBEDDING_DIM, \n",
        "            HIDDEN_DIM, \n",
        "            OUTPUT_DIM, \n",
        "            N_LAYERS, \n",
        "            BIDIRECTIONAL, \n",
        "            DROPOUT, \n",
        "            PAD_IDX)\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LSTM_net(\n",
            "  (embedding): Embedding(12931, 200, padding_idx=1)\n",
            "  (rnn): LSTM(200, 256, num_layers=2, dropout=0.2, bidirectional=True)\n",
            "  (fc1): Linear(in_features=512, out_features=256, bias=True)\n",
            "  (fc2): Linear(in_features=256, out_features=1, bias=True)\n",
            "  (dropout): Dropout(p=0.2, inplace=False)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mHWuZynWdlDn",
        "outputId": "e4c051c1-1002-47d1-c350-de12bc8931d7"
      },
      "source": [
        "#word2idx = {word: ind for ind, word in enumerate(vocab)}\n",
        "\n",
        "# word2idx = {'i': 0, 'am': 1, 'new': 2, 'to': 3, 'pytorch': 4, 'having': 5, 'fun': 6}\n",
        "\n",
        "#encoded_sentences = [word2idx[word] for word in train_ds]\n",
        "pretrained_embeddings = TEXT.vocab.vectors\n",
        "\n",
        "print(pretrained_embeddings.shape)\n",
        "model.embedding.weight.data.copy_(pretrained_embeddings)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([12931, 200])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.3833,  0.1607, -0.3276,  ...,  0.4720, -0.4945,  0.3688],\n",
              "        ...,\n",
              "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [-0.1776,  0.2225,  0.3361,  ...,  0.5330,  0.6103, -0.4537]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "prdA1BLud9jE",
        "outputId": "9a22ee20-3ca4-473e-e2bd-e5e0123cbdf6"
      },
      "source": [
        "#  to initiaise padded to zeros\n",
        "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "\n",
        "print(model.embedding.weight.data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.3833,  0.1607, -0.3276,  ...,  0.4720, -0.4945,  0.3688],\n",
            "        ...,\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [-0.1776,  0.2225,  0.3361,  ...,  0.5330,  0.6103, -0.4537]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxmvybQ3gJvo"
      },
      "source": [
        "model.to(device) #CNN to GPU\n",
        "\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "#criterion = nn.CrossEntropyLoss()\n",
        "#optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkX84bUQgPE3"
      },
      "source": [
        "def binary_accuracy(preds, y):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
        "    \"\"\"\n",
        "\n",
        "    #round predictions to the closest integer\n",
        "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
        "    correct = (rounded_preds == y).float() #convert into float for division \n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyVuYA54ghbI"
      },
      "source": [
        "# training function \n",
        "def train(model, iterator):\n",
        "    #batch.text\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    model.train()\n",
        "    for batch in iterator:\n",
        "        text, text_lengths = batch.lemmatize_text\n",
        "        optimizer.zero_grad()\n",
        "        predictions = model(text, text_lengths).squeeze(1)\n",
        "        loss = criterion(predictions, batch.label)\n",
        "        acc = binary_accuracy(predictions, batch.label)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        \n",
        "\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bt3TPgwmCt2L"
      },
      "source": [
        "def evaluate(model, iterator):\n",
        "    \n",
        "    epoch_acc = 0\n",
        "    model.eval()\n",
        "    #batch.text bood avaz kardam\n",
        "    with torch.no_grad():\n",
        "        for batch in iterator:\n",
        "            text, text_lengths = batch.lemmatize_text\n",
        "            predictions = model(text, text_lengths).squeeze(1)\n",
        "            acc = binary_accuracy(predictions, batch.label)\n",
        "            \n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_acc / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEVGuDH9aeu2"
      },
      "source": [
        "t = time.time()\n",
        "loss=[]\n",
        "acc=[]\n",
        "val_acc=[]\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    \n",
        "    train_loss, train_acc = train(model, train_iterator)\n",
        "    valid_acc = evaluate(model, valid_iterator)\n",
        "    \n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Acc: {valid_acc*100:.2f}%')\n",
        "    \n",
        "    loss.append(train_loss)\n",
        "    acc.append(train_acc)\n",
        "    val_acc.append(valid_acc)\n",
        "    \n",
        "print(f'time:{time.time()-t:.3f}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "rbrEo-t1MhJu",
        "outputId": "fd2796e3-a7dc-4a58-b7f0-e5a6954dc041"
      },
      "source": [
        "plt.xlabel(\"runs\")\n",
        "plt.ylabel(\"normalised measure of loss/accuracy\")\n",
        "x_len=list(range(len(acc)))\n",
        "plt.axis([0, max(x_len), 0, 1])\n",
        "plt.title('result of LSTM')\n",
        "loss=np.asarray(loss)/max(loss)\n",
        "plt.plot(x_len, loss, 'r.',label=\"loss\")\n",
        "plt.plot(x_len, acc, 'b.', label=\"accuracy\")\n",
        "plt.plot(x_len, val_acc, 'g.', label=\"val_accuracy\")\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.2)\n",
        "plt.show"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function matplotlib.pyplot.show>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}